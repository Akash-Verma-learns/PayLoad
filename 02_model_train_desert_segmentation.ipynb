{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Off-Road Semantic Scene Segmentation - Model Training\n",
    "## Track 2: Desert Environment Segmentation with U-Net\n",
    "\n",
    "This notebook implements model training, evaluation, and inference for the desert semantic segmentation challenge.\n",
    "\n",
    "**Evaluation Metric:** Intersection over Union (IoU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Import from preprocessing notebook\n",
    "# (In practice, you would import or redefine the Dataset class here)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "# Model configuration\n",
    "NUM_CLASSES = 10\n",
    "HEIGHT = 512\n",
    "WIDTH = 512\n",
    "\n",
    "# Paths\n",
    "CHECKPOINT_DIR = './checkpoints'\n",
    "OUTPUT_DIR = './outputs'\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Training settings\n",
    "SAVE_INTERVAL = 5  # Save checkpoint every N epochs\n",
    "NUM_WORKERS = 4  # For DataLoader\n",
    "\n",
    "print(f\"Training Configuration:\")\n",
    "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  Image Size: {HEIGHT}x{WIDTH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Architecture - U-Net with ResNet Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        \n",
    "        # Input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "        \n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"U-Net architecture for semantic segmentation\"\"\"\n",
    "    \n",
    "    def __init__(self, n_channels=3, n_classes=10, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "        \n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = UNet(n_channels=3, n_classes=NUM_CLASSES, bilinear=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nModel: U-Net\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Loss Functions and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedLoss(nn.Module):\n",
    "    \"\"\"Combined Cross Entropy + Dice Loss for better segmentation\"\"\"\n",
    "    \n",
    "    def __init__(self, weight=None, ce_weight=0.5, dice_weight=0.5):\n",
    "        super().__init__()\n",
    "        self.ce_weight = ce_weight\n",
    "        self.dice_weight = dice_weight\n",
    "        self.ce_loss = nn.CrossEntropyLoss(weight=weight)\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        # Cross Entropy Loss\n",
    "        ce = self.ce_loss(pred, target)\n",
    "        \n",
    "        # Dice Loss\n",
    "        pred_softmax = F.softmax(pred, dim=1)\n",
    "        target_one_hot = F.one_hot(target, num_classes=pred.shape[1]).permute(0, 3, 1, 2).float()\n",
    "        \n",
    "        intersection = (pred_softmax * target_one_hot).sum(dim=(2, 3))\n",
    "        union = pred_softmax.sum(dim=(2, 3)) + target_one_hot.sum(dim=(2, 3))\n",
    "        \n",
    "        dice = (2. * intersection + 1e-7) / (union + 1e-7)\n",
    "        dice_loss = 1 - dice.mean()\n",
    "        \n",
    "        return self.ce_weight * ce + self.dice_weight * dice_loss\n",
    "\n",
    "\n",
    "def calculate_iou(pred, target, num_classes):\n",
    "    \"\"\"\n",
    "    Calculate Intersection over Union (IoU) for semantic segmentation\n",
    "    \n",
    "    Args:\n",
    "        pred: Predicted segmentation (B, C, H, W) or (B, H, W)\n",
    "        target: Ground truth segmentation (B, H, W)\n",
    "        num_classes: Number of classes\n",
    "    \n",
    "    Returns:\n",
    "        mean_iou: Mean IoU across all classes\n",
    "        class_iou: IoU for each class\n",
    "    \"\"\"\n",
    "    if pred.dim() == 4:\n",
    "        pred = torch.argmax(pred, dim=1)\n",
    "    \n",
    "    ious = []\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        pred_cls = (pred == cls)\n",
    "        target_cls = (target == cls)\n",
    "        \n",
    "        intersection = (pred_cls & target_cls).sum().float()\n",
    "        union = (pred_cls | target_cls).sum().float()\n",
    "        \n",
    "        if union == 0:\n",
    "            iou = torch.tensor(float('nan'))\n",
    "        else:\n",
    "            iou = intersection / union\n",
    "        \n",
    "        ious.append(iou.item())\n",
    "    \n",
    "    # Calculate mean IoU (ignoring NaN values)\n",
    "    valid_ious = [iou for iou in ious if not np.isnan(iou)]\n",
    "    mean_iou = np.mean(valid_ious) if valid_ious else 0.0\n",
    "    \n",
    "    return mean_iou, ious\n",
    "\n",
    "\n",
    "# Initialize loss function\n",
    "criterion = CombinedLoss(ce_weight=0.5, dice_weight=0.5)\n",
    "print(\"Loss function: Combined CE + Dice Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training and Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_iou = 0.0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc='Training')\n",
    "    for images, masks in pbar:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        with torch.no_grad():\n",
    "            mean_iou, _ = calculate_iou(outputs, masks, NUM_CLASSES)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        running_iou += mean_iou\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'iou': f'{mean_iou:.4f}'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_iou = running_iou / len(dataloader)\n",
    "    \n",
    "    return epoch_loss, epoch_iou\n",
    "\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    \"\"\"Validate for one epoch\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_iou = 0.0\n",
    "    all_class_ious = [[] for _ in range(NUM_CLASSES)]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc='Validation')\n",
    "        for images, masks in pbar:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            mean_iou, class_ious = calculate_iou(outputs, masks, NUM_CLASSES)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_iou += mean_iou\n",
    "            \n",
    "            # Collect class-wise IoUs\n",
    "            for cls_idx, iou in enumerate(class_ious):\n",
    "                if not np.isnan(iou):\n",
    "                    all_class_ious[cls_idx].append(iou)\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'iou': f'{mean_iou:.4f}'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_iou = running_iou / len(dataloader)\n",
    "    \n",
    "    # Calculate average IoU per class\n",
    "    class_iou_avg = [np.mean(ious) if ious else 0.0 for ious in all_class_ious]\n",
    "    \n",
    "    return epoch_loss, epoch_iou, class_iou_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: You need to create train_loader and val_loader from your datasets\n",
    "# This assumes you've run the preprocessing notebook or imported the datasets\n",
    "\n",
    "# Example (uncomment and modify):\n",
    "# from your_preprocessing_module import train_dataset, val_dataset\n",
    "# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_iou': [],\n",
    "    'val_loss': [],\n",
    "    'val_iou': [],\n",
    "    'learning_rates': []\n",
    "}\n",
    "\n",
    "best_val_iou = 0.0\n",
    "best_epoch = 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING START\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Uncomment to run training\n",
    "'''\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_iou = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_iou, class_ious = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_iou)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Record history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_iou'].append(train_iou)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_iou'].append(val_iou)\n",
    "    history['learning_rates'].append(current_lr)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train IoU: {train_iou:.4f}\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f} | Val IoU:   {val_iou:.4f}\")\n",
    "    print(f\"  Learning Rate: {current_lr:.2e}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_iou > best_val_iou:\n",
    "        best_val_iou = val_iou\n",
    "        best_epoch = epoch + 1\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_iou': val_iou,\n",
    "            'class_ious': class_ious,\n",
    "        }, os.path.join(CHECKPOINT_DIR, 'best_model.pth'))\n",
    "        print(f\"  ✓ New best model saved! (IoU: {val_iou:.4f})\")\n",
    "    \n",
    "    # Save checkpoint periodically\n",
    "    if (epoch + 1) % SAVE_INTERVAL == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_iou': val_iou,\n",
    "        }, os.path.join(CHECKPOINT_DIR, f'checkpoint_epoch_{epoch+1}.pth'))\n",
    "        print(f\"  Checkpoint saved: epoch_{epoch+1}.pth\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best Validation IoU: {best_val_iou:.4f} at epoch {best_epoch}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training curves\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "    axes[0].plot(history['val_loss'], label='Val Loss', marker='s')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # IoU\n",
    "    axes[1].plot(history['train_iou'], label='Train IoU', marker='o')\n",
    "    axes[1].plot(history['val_iou'], label='Val IoU', marker='s')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('IoU')\n",
    "    axes[1].set_title('Training and Validation IoU')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning Rate\n",
    "    axes[2].plot(history['learning_rates'], marker='o', color='green')\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('Learning Rate')\n",
    "    axes[2].set_title('Learning Rate Schedule')\n",
    "    axes[2].set_yscale('log')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, 'training_curves.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Uncomment to plot (after training)\n",
    "# plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detailed_evaluation(model, dataloader, device, class_names):\n",
    "    \"\"\"Perform detailed evaluation with class-wise metrics\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    all_class_ious = [[] for _ in range(NUM_CLASSES)]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(dataloader, desc='Evaluating'):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            mean_iou, class_ious = calculate_iou(outputs, masks, NUM_CLASSES)\n",
    "            \n",
    "            for cls_idx, iou in enumerate(class_ious):\n",
    "                if not np.isnan(iou):\n",
    "                    all_class_ious[cls_idx].append(iou)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    results = []\n",
    "    for cls_idx, (class_name, ious) in enumerate(zip(class_names, all_class_ious)):\n",
    "        if ious:\n",
    "            mean = np.mean(ious)\n",
    "            std = np.std(ious)\n",
    "            results.append({\n",
    "                'class': class_name,\n",
    "                'iou_mean': mean,\n",
    "                'iou_std': std,\n",
    "                'count': len(ious)\n",
    "            })\n",
    "        else:\n",
    "            results.append({\n",
    "                'class': class_name,\n",
    "                'iou_mean': 0.0,\n",
    "                'iou_std': 0.0,\n",
    "                'count': 0\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def print_evaluation_results(results):\n",
    "    \"\"\"Print evaluation results in a formatted table\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EVALUATION RESULTS - CLASS-WISE IoU\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"{'Class':<20} {'Mean IoU':<15} {'Std Dev':<15} {'Samples'}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    mean_ious = []\n",
    "    for result in results:\n",
    "        print(f\"{result['class']:<20} {result['iou_mean']:<15.4f} {result['iou_std']:<15.4f} {result['count']}\")\n",
    "        if result['iou_mean'] > 0:\n",
    "            mean_ious.append(result['iou_mean'])\n",
    "    \n",
    "    print(\"-\"*70)\n",
    "    print(f\"{'Overall mIoU':<20} {np.mean(mean_ious):<15.4f}\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Load best model and evaluate\n",
    "# Uncomment to run evaluation\n",
    "'''\n",
    "checkpoint = torch.load(os.path.join(CHECKPOINT_DIR, 'best_model.pth'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "CLASS_NAMES = ['Trees', 'Lush Bushes', 'Dry Grass', 'Dry Bushes', \n",
    "               'Ground Clutter', 'Flowers', 'Logs', 'Rocks', 'Landscape', 'Sky']\n",
    "\n",
    "results = detailed_evaluation(model, val_loader, device, CLASS_NAMES)\n",
    "print_evaluation_results(results)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualization of Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, dataset, device, num_samples=5, class_colors=None):\n",
    "    \"\"\"Visualize model predictions\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    if class_colors is None:\n",
    "        class_colors = plt.cm.tab10(np.linspace(0, 1, NUM_CLASSES))[:, :3] * 255\n",
    "    \n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "    \n",
    "    for idx in indices:\n",
    "        image, mask_gt = dataset[idx]\n",
    "        \n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            image_input = image.unsqueeze(0).to(device)\n",
    "            output = model(image_input)\n",
    "            pred = torch.argmax(output, dim=1).squeeze(0).cpu().numpy()\n",
    "        \n",
    "        # Denormalize image\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        image_vis = image * std + mean\n",
    "        image_vis = torch.clamp(image_vis, 0, 1)\n",
    "        image_np = image_vis.permute(1, 2, 0).numpy()\n",
    "        \n",
    "        # Create colored masks\n",
    "        mask_gt_np = mask_gt.numpy()\n",
    "        \n",
    "        mask_gt_color = np.zeros((*mask_gt_np.shape, 3), dtype=np.uint8)\n",
    "        mask_pred_color = np.zeros((*pred.shape, 3), dtype=np.uint8)\n",
    "        \n",
    "        for cls in range(NUM_CLASSES):\n",
    "            mask_gt_color[mask_gt_np == cls] = class_colors[cls]\n",
    "            mask_pred_color[pred == cls] = class_colors[cls]\n",
    "        \n",
    "        # Calculate IoU for this sample\n",
    "        iou, _ = calculate_iou(\n",
    "            torch.from_numpy(pred).unsqueeze(0),\n",
    "            torch.from_numpy(mask_gt_np).unsqueeze(0),\n",
    "            NUM_CLASSES\n",
    "        )\n",
    "        \n",
    "        # Plot\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "        \n",
    "        axes[0].imshow(image_np)\n",
    "        axes[0].set_title('Input Image')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(mask_gt_color)\n",
    "        axes[1].set_title('Ground Truth')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        axes[2].imshow(mask_pred_color)\n",
    "        axes[2].set_title(f'Prediction (IoU: {iou:.3f})')\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        # Overlay\n",
    "        overlay = image_np * 0.6 + mask_pred_color / 255 * 0.4\n",
    "        axes[3].imshow(overlay)\n",
    "        axes[3].set_title('Overlay')\n",
    "        axes[3].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUTPUT_DIR, f'prediction_{idx}.png'), dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "# Uncomment to visualize\n",
    "# visualize_predictions(model, val_dataset, device, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Inference on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_set(model, test_loader, device, output_dir):\n",
    "    \"\"\"Generate predictions for test set\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"Generating test predictions...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, filenames in tqdm(test_loader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            predictions = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            \n",
    "            # Save predictions\n",
    "            for pred, filename in zip(predictions, filenames):\n",
    "                # Save as PNG\n",
    "                pred_img = Image.fromarray(pred.astype(np.uint8))\n",
    "                save_path = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_pred.png\")\n",
    "                pred_img.save(save_path)\n",
    "    \n",
    "    print(f\"Test predictions saved to {output_dir}\")\n",
    "\n",
    "# Uncomment to generate test predictions\n",
    "# test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "# predict_test_set(model, test_loader, device, os.path.join(OUTPUT_DIR, 'test_predictions'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Final Model and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training configuration and results\n",
    "metadata = {\n",
    "    'model': 'U-Net',\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    'image_size': [HEIGHT, WIDTH],\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'num_epochs': NUM_EPOCHS,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'optimizer': 'AdamW',\n",
    "    'loss_function': 'Combined CE + Dice',\n",
    "    'best_val_iou': best_val_iou if 'best_val_iou' in locals() else None,\n",
    "    'best_epoch': best_epoch if 'best_epoch' in locals() else None,\n",
    "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "}\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, 'training_metadata.json'), 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"Training metadata saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook provides:\n",
    "1. ✅ U-Net model architecture for semantic segmentation\n",
    "2. ✅ Combined loss function (CE + Dice)\n",
    "3. ✅ IoU metric calculation\n",
    "4. ✅ Training and validation loops\n",
    "5. ✅ Visualization tools\n",
    "6. ✅ Test set inference\n",
    "\n",
    "**For Competition Submission:**\n",
    "1. Train the model on the full training set\n",
    "2. Evaluate on the validation set\n",
    "3. Generate predictions for the unseen test set\n",
    "4. Analyze failure cases\n",
    "5. Document your methodology\n",
    "\n",
    "**Potential Improvements:**\n",
    "- Try different architectures (DeepLabV3+, SegFormer)\n",
    "- Use pretrained encoders (ResNet, EfficientNet)\n",
    "- Experiment with loss functions (Focal Loss, Tversky Loss)\n",
    "- Apply test-time augmentation\n",
    "- Ensemble multiple models\n",
    "- Post-processing (CRF, conditional random fields)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
